Una vez realizado todo el laboratorio y seguir el paso a paso de hdfs_scripts.txt tendran esto como resultado:

Datos cargados en HDFS en el nodo master
![image](https://github.com/user-attachments/assets/eeaba0be-f91d-47b3-bdd3-1cb734ccb71e)
![image](https://github.com/user-attachments/assets/47e135e7-8e37-454e-92d3-69f25df56ee2)

Ingresar en Hue
![image](https://github.com/user-attachments/assets/9b6cd46a-6dd2-4f06-ac72-ca1236ff0b30)
![image](https://github.com/user-attachments/assets/f1c57886-380c-4213-91a1-989cd2019a26)

Creacion de las carpetas dataset y onu y subida de los archivos de export-data.csv y hdi-data.csv
![image](https://github.com/user-attachments/assets/6f3e2a60-d7bb-4a25-9c43-5909b29569a0)
![image](https://github.com/user-attachments/assets/a01fa891-f9f9-419d-bb33-d6c2f5ab9479)
![image](https://github.com/user-attachments/assets/07c62ef2-b3ad-462c-a19a-4ec382cb57c8)
![image](https://github.com/user-attachments/assets/13212a0f-c9c6-4994-8520-1e608a9c9c08)

Archivos cargados en el Bucket S3
![image](https://github.com/user-attachments/assets/9c1c7c91-a007-4084-a143-8b5370cc37b8)
